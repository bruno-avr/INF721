# INF 721 - Final Project

**Student:** Bruno Alencar Vieira de Rezende  
**Enrollment Number:** ES102008

## Introduction

This work implements the Transformer model introduced in "Attention Is All You Need" by Vaswani et al. (2017) using PyTorch, focusing on testing the results achieved on the WMT 2014 English-to-German translation task. The project includes dataset preprocessing, environment setup, and building key Transformer components like multi-head attention and the encoder-decoder structure, while adapting training to resource constraints.

## Instructions

There is a Jupyter notebook with the code in the root of the project, named `INF 721 - Final Project - Bruno Rezende - 102008.ipynb`.
