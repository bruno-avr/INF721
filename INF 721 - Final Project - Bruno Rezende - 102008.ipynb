{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"toc_visible":true,"gpuType":"T4","authorship_tag":"ABX9TyMugnQQQS0V6yIHVsg7j6wm"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","source":["!pip install datasets"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"g0CTVmrdI4i3","executionInfo":{"status":"ok","timestamp":1734300699544,"user_tz":180,"elapsed":2660,"user":{"displayName":"Bruno Alencar Vieira de Rezende","userId":"01054554116542735806"}},"outputId":"3ccba1be-040c-4689-837c-b380b21586d9"},"execution_count":56,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: datasets in /usr/local/lib/python3.10/dist-packages (3.2.0)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from datasets) (3.16.1)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (1.26.4)\n","Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (17.0.0)\n","Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.3.8)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (2.2.2)\n","Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.10/dist-packages (from datasets) (2.32.3)\n","Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.10/dist-packages (from datasets) (4.66.6)\n","Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets) (3.5.0)\n","Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.70.16)\n","Requirement already satisfied: fsspec<=2024.9.0,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from fsspec[http]<=2024.9.0,>=2023.1.0->datasets) (2024.9.0)\n","Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.11.10)\n","Requirement already satisfied: huggingface-hub>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.26.5)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from datasets) (24.2)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (6.0.2)\n","Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (2.4.4)\n","Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.1)\n","Requirement already satisfied: async-timeout<6.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (4.0.3)\n","Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (24.2.0)\n","Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.5.0)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.1.0)\n","Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (0.2.1)\n","Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.18.3)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.23.0->datasets) (4.12.2)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (3.4.0)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (3.10)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (2.2.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (2024.8.30)\n","Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.8.2)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.2)\n","Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.2)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n"]}]},{"cell_type":"code","execution_count":110,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"HzWh7lV1dIlP","executionInfo":{"status":"ok","timestamp":1734309741967,"user_tz":180,"elapsed":248,"user":{"displayName":"Bruno Alencar Vieira de Rezende","userId":"01054554116542735806"}},"outputId":"96db7733-6db4-4bff-e097-3209742f7900"},"outputs":[{"output_type":"stream","name":"stderr","text":["[nltk_data] Downloading package punkt to /root/nltk_data...\n","[nltk_data]   Package punkt is already up-to-date!\n","[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n","[nltk_data]   Package punkt_tab is already up-to-date!\n"]},{"output_type":"execute_result","data":{"text/plain":["True"]},"metadata":{},"execution_count":110}],"source":["import torch\n","import torch.nn as nn\n","from torch.utils.data import DataLoader, Dataset\n","from datasets import load_dataset\n","import nltk\n","from nltk.tokenize import word_tokenize\n","from collections import Counter\n","import torch.optim as optim\n","from tqdm import tqdm\n","from nltk.translate.bleu_score import sentence_bleu, corpus_bleu\n","from nltk.translate.bleu_score import SmoothingFunction\n","from concurrent.futures import ThreadPoolExecutor\n","import threading\n","\n","nltk.download(\"punkt\")\n","nltk.download('punkt_tab')"]},{"cell_type":"code","source":["device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"],"metadata":{"id":"IHQ1TRaGJIKS","executionInfo":{"status":"ok","timestamp":1734300699544,"user_tz":180,"elapsed":3,"user":{"displayName":"Bruno Alencar Vieira de Rezende","userId":"01054554116542735806"}}},"execution_count":58,"outputs":[]},{"cell_type":"markdown","source":["# Loading Dataset"],"metadata":{"id":"hlTgsY4JJOhL"}},{"cell_type":"code","source":["dataset = load_dataset(\"wmt14\", \"de-en\")"],"metadata":{"id":"J-WV7FUtJQPV","executionInfo":{"status":"ok","timestamp":1734300702891,"user_tz":180,"elapsed":3350,"user":{"displayName":"Bruno Alencar Vieira de Rezende","userId":"01054554116542735806"}}},"execution_count":59,"outputs":[]},{"cell_type":"code","source":["dataset['train'] = dataset['train'].select(range(500000))"],"metadata":{"id":"ERvJ3FMzJWkA","executionInfo":{"status":"ok","timestamp":1734300974787,"user_tz":180,"elapsed":261,"user":{"displayName":"Bruno Alencar Vieira de Rezende","userId":"01054554116542735806"}}},"execution_count":72,"outputs":[]},{"cell_type":"markdown","source":["# Transformer Architecture"],"metadata":{"id":"umefzeInJbJa"}},{"cell_type":"code","source":["class SelfAttention(nn.Module):\n","  def __init__(self, embed_size, num_heads):\n","    super(SelfAttention, self).__init__()\n","    self.embed_size = embed_size\n","    self.num_heads = num_heads\n","    self.head_dim = embed_size // num_heads\n","\n","    assert (\n","      self.head_dim * self.num_heads == self.embed_size\n","    ), \"The embed_size must be divisible by num_heads.\"\n","\n","    self.values = nn.Linear(embed_size, embed_size)\n","    self.keys = nn.Linear(embed_size, embed_size)\n","    self.queries = nn.Linear(embed_size, embed_size)\n","    self.fc_out = nn.Linear(embed_size, embed_size)\n","\n","  def forward(self, values, keys, queries, mask):\n","    N = queries.shape[0] # Number of training examples\n","\n","    values_len, keys_len, queries_len = values.shape[1], keys.shape[1], queries.shape[1]\n","\n","    values = self.values(values)\n","    keys = self.keys(keys)\n","    queries = self.queries(queries)\n","\n","    # Split the embedding into self.num_heads different parts\n","    # embed_size => self.num_heads * self.head_dim\n","    values = values.reshape(N, values_len, self.num_heads, self.head_dim)\n","    keys = keys.reshape(N, keys_len, self.num_heads, self.head_dim)\n","    queries = queries.reshape(N, queries_len, self.num_heads, self.head_dim)\n","\n","    # queries shape: (N, query_len, num_heads, heads_dim) = nqhd\n","    # keys shape: (N, key_len, num_heads, heads_dim) = nkhd\n","    # temp shape: (N, num_heads, query_len, key_len) = nhqk\n","    temp = torch.einsum(\"nqhd,nkhd->nhqk\", [queries, keys])\n","\n","    if mask is not None:\n","      MINUS_INF = float(\"-1e16\")\n","      temp = temp.masked_fill(mask == 0, MINUS_INF)\n","\n","    attention = torch.softmax(temp / (self.embed_size ** (1/2)), dim=3)\n","\n","    # attention shape: (N, num_heads, query_len, key_len)\n","    # values shape: (N, value_len, num_heads, heads_dim)\n","    # out shape: (N, query_len, num_heads, head_dim)\n","    out = torch.einsum(\"nhql,nlhd->nqhd\", [attention, values])\n","\n","    # concatenate\n","    out = out.reshape(\n","      N, queries_len, self.num_heads * self.head_dim\n","    )\n","\n","    out = self.fc_out(out)\n","\n","    return out"],"metadata":{"id":"qF2ZwT56dPtK","executionInfo":{"status":"ok","timestamp":1734300974787,"user_tz":180,"elapsed":7,"user":{"displayName":"Bruno Alencar Vieira de Rezende","userId":"01054554116542735806"}}},"execution_count":73,"outputs":[]},{"cell_type":"code","source":["class TransformerBlock(nn.Module):\n","  def __init__(self, embed_size, num_heads, dropout, forward_expansion):\n","    super(TransformerBlock, self).__init__()\n","    self.attention = SelfAttention(embed_size, num_heads)\n","\n","    self.norm1 = nn.LayerNorm(embed_size)\n","\n","    self.feed_forward = nn.Sequential(\n","      nn.Linear(embed_size, forward_expansion * embed_size),\n","      nn.ReLU(),\n","      nn.Linear(forward_expansion * embed_size, embed_size),\n","    )\n","\n","    self.norm2 = nn.LayerNorm(embed_size)\n","\n","    self.dropout = nn.Dropout(dropout)\n","\n","  def forward(self, values, keys, queries, mask):\n","    attention_out = self.attention(values, keys, queries, mask)\n","\n","    norm1_out = self.dropout(self.norm1(attention_out + queries)) # the queries represent the skip connection\n","\n","    feed_forward_out = self.feed_forward(norm1_out)\n","\n","    out = self.dropout(self.norm2(feed_forward_out + norm1_out)) # the norm1_out represent the skip connection\n","\n","    return out"],"metadata":{"id":"M_W9xrXIj69B","executionInfo":{"status":"ok","timestamp":1734300974787,"user_tz":180,"elapsed":6,"user":{"displayName":"Bruno Alencar Vieira de Rezende","userId":"01054554116542735806"}}},"execution_count":74,"outputs":[]},{"cell_type":"code","source":["class Encoder(nn.Module):\n","  def __init__(\n","    self,\n","    vocab_size,\n","    embed_size,\n","    num_layers,\n","    num_heads,\n","    device,\n","    forward_expansion,\n","    dropout,\n","    max_length # for positional embedding\n","  ):\n","    super(Encoder, self).__init__()\n","    self.embed_size = embed_size\n","    self.device = device\n","    self.word_embedding = nn.Embedding(vocab_size, embed_size)\n","    self.position_embedding = nn.Embedding(max_length, embed_size)\n","\n","    self.layers = nn.ModuleList(\n","      [\n","        TransformerBlock(\n","          embed_size,\n","          num_heads,\n","          dropout=dropout,\n","          forward_expansion=forward_expansion\n","        )\n","        for _ in range(num_layers)\n","      ]\n","    )\n","\n","    self.dropout = nn.Dropout(dropout)\n","\n","  def forward(self, x, mask):\n","    N, seq_length = x.shape\n","    positions = torch.arange(0, seq_length).expand(N, seq_length).to(self.device)\n","    out = self.word_embedding(x) + self.position_embedding(positions)\n","    out = self.dropout(out)\n","\n","    for layer in self.layers:\n","      out = layer(out, out, out, mask) # values, keys and queries are all the same\n","\n","    return out"],"metadata":{"id":"MekRWVhAm_Y8","executionInfo":{"status":"ok","timestamp":1734300974787,"user_tz":180,"elapsed":6,"user":{"displayName":"Bruno Alencar Vieira de Rezende","userId":"01054554116542735806"}}},"execution_count":75,"outputs":[]},{"cell_type":"code","source":["class DecoderBlock(nn.Module):\n","  def __init__(\n","      self,\n","      embed_size,\n","      num_heads,\n","      forward_expansion,\n","      dropout,\n","      device\n","    ):\n","    super(DecoderBlock, self).__init__()\n","    self.attention = SelfAttention(embed_size, num_heads)\n","    self.norm = nn.LayerNorm(embed_size)\n","    self.transformer_block = TransformerBlock(\n","      embed_size, num_heads, dropout, forward_expansion\n","    )\n","    self.dropout = nn.Dropout(dropout)\n","\n","  def forward(self, x, value, key, src_mask, trg_mask):\n","    attention_out = self.attention(x, x, x, trg_mask)\n","    norm_out = self.dropout(self.norm(attention_out + x)) # the x represents the skip connection\n","    out = self.transformer_block(value, key, norm_out, src_mask)\n","    return out"],"metadata":{"id":"mH0UZ2iYot98","executionInfo":{"status":"ok","timestamp":1734300974787,"user_tz":180,"elapsed":6,"user":{"displayName":"Bruno Alencar Vieira de Rezende","userId":"01054554116542735806"}}},"execution_count":76,"outputs":[]},{"cell_type":"code","source":["class Decoder(nn.Module):\n","  def __init__(\n","    self,\n","    vocab_size,\n","    embed_size,\n","    num_layers,\n","    num_heads,\n","    forward_expansion,\n","    dropout,\n","    device,\n","    max_length,\n","  ):\n","    super(Decoder, self).__init__()\n","    self.device = device\n","    self.word_embedding = nn.Embedding(vocab_size, embed_size)\n","    self.position_embedding = nn.Embedding(max_length, embed_size)\n","\n","    self.layers = nn.ModuleList(\n","      [\n","        DecoderBlock(embed_size, num_heads, forward_expansion, dropout, device)\n","        for _ in range(num_layers)\n","      ]\n","    )\n","    self.fc_out = nn.Linear(embed_size, vocab_size)\n","    self.dropout = nn.Dropout(dropout)\n","\n","  def forward(self, x, enc_out, src_mask, trg_mask):\n","    N, seq_length = x.shape\n","    positions = torch.arange(0, seq_length).expand(N, seq_length).to(self.device)\n","    x = self.dropout((self.word_embedding(x) + self.position_embedding(positions)))\n","\n","    for layer in self.layers:\n","      x = layer(x, enc_out, enc_out, src_mask, trg_mask)\n","\n","    out = self.fc_out(x)\n","\n","    return out"],"metadata":{"id":"dcTw5uy3pv6h","executionInfo":{"status":"ok","timestamp":1734300974788,"user_tz":180,"elapsed":5,"user":{"displayName":"Bruno Alencar Vieira de Rezende","userId":"01054554116542735806"}}},"execution_count":77,"outputs":[]},{"cell_type":"code","source":["class Transformer(nn.Module):\n","  def __init__(\n","    self,\n","    src_vocab_size,\n","    trg_vocab_size,\n","    src_pad_idx,\n","    trg_pad_idx,\n","    embed_size=512,\n","    num_layers=6,\n","    forward_expansion=4,\n","    heads=8,\n","    dropout=0,\n","    device=\"cpu\",\n","    max_length=100,\n","  ):\n","\n","    super(Transformer, self).__init__()\n","\n","    self.encoder = Encoder(\n","      src_vocab_size,\n","      embed_size,\n","      num_layers,\n","      heads,\n","      device,\n","      forward_expansion,\n","      dropout,\n","      max_length,\n","    )\n","\n","    self.decoder = Decoder(\n","      trg_vocab_size,\n","      embed_size,\n","      num_layers,\n","      heads,\n","      forward_expansion,\n","      dropout,\n","      device,\n","      max_length,\n","    )\n","\n","    self.src_pad_idx = src_pad_idx\n","    self.trg_pad_idx = trg_pad_idx\n","    self.device = device\n","\n","  def make_src_mask(self, src):\n","    src_mask = (src != self.src_pad_idx).unsqueeze(1).unsqueeze(2)\n","    # (N, 1, 1, src_len)\n","    return src_mask.to(self.device)\n","\n","  def make_trg_mask(self, trg):\n","    N, trg_len = trg.shape\n","    trg_mask = torch.tril(torch.ones((trg_len, trg_len))).expand(\n","        N, 1, trg_len, trg_len\n","    )\n","\n","    return trg_mask.to(self.device)\n","\n","  def forward(self, src, trg):\n","    src_mask = self.make_src_mask(src)\n","    trg_mask = self.make_trg_mask(trg)\n","    enc_src = self.encoder(src, src_mask)\n","    out = self.decoder(trg, enc_src, src_mask, trg_mask)\n","    return out"],"metadata":{"id":"Cr5MuxJarGkh","executionInfo":{"status":"ok","timestamp":1734300974788,"user_tz":180,"elapsed":4,"user":{"displayName":"Bruno Alencar Vieira de Rezende","userId":"01054554116542735806"}}},"execution_count":78,"outputs":[]},{"cell_type":"code","source":["device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","print(device)\n","\n","x = torch.tensor([[1, 5, 6, 4, 3, 9, 5, 2, 0], [1, 8, 7, 3, 4, 5, 6, 7, 2]]).to(\n","    device\n",")\n","trg = torch.tensor([[1, 7, 4, 3, 5, 9, 2, 0], [1, 5, 6, 2, 4, 7, 6, 2]]).to(device)\n","\n","src_pad_idx = 0\n","trg_pad_idx = 0\n","src_vocab_size = 10\n","trg_vocab_size = 10\n","model = Transformer(src_vocab_size, trg_vocab_size, src_pad_idx, trg_pad_idx, device=device).to(\n","    device\n",")\n","out = model(x, trg[:, :-1])\n","print(out.shape)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_TJ87CfMrrw1","executionInfo":{"status":"ok","timestamp":1734300975189,"user_tz":180,"elapsed":404,"user":{"displayName":"Bruno Alencar Vieira de Rezende","userId":"01054554116542735806"}},"outputId":"7f86bca2-bf29-4584-cebe-48ef5f41a266"},"execution_count":79,"outputs":[{"output_type":"stream","name":"stdout","text":["cuda\n","torch.Size([2, 7, 10])\n"]}]},{"cell_type":"markdown","source":[],"metadata":{"id":"mwXELF1xI1Ho"}},{"cell_type":"markdown","source":["# Preprocessing"],"metadata":{"id":"YhcfsddgIyHU"}},{"cell_type":"code","source":["def build_vocab(data, language, vocab_size=10000):\n","  token_counter = Counter()\n","  for translation in data[\"translation\"]:\n","    tokens = word_tokenize(translation[language].lower())\n","    token_counter.update(tokens)\n","  most_common = token_counter.most_common(vocab_size - 4)  # Reserve 4 for special tokens\n","  vocab = {word: idx + 4 for idx, (word, _) in enumerate(most_common)}\n","  vocab[\"<PAD>\"] = 0 # Padding\n","  vocab[\"<SOS>\"] = 1 # Start of sequence\n","  vocab[\"<EOS>\"] = 2 # End of sequence\n","  vocab[\"<UNK>\"] = 3 # Unknown\n","  return vocab"],"metadata":{"id":"x_JQADASJnvI","executionInfo":{"status":"ok","timestamp":1734300975189,"user_tz":180,"elapsed":2,"user":{"displayName":"Bruno Alencar Vieira de Rezende","userId":"01054554116542735806"}}},"execution_count":80,"outputs":[]},{"cell_type":"code","source":["src_vocab = build_vocab(dataset[\"train\"], \"en\")\n","trg_vocab = build_vocab(dataset[\"train\"], \"de\")"],"metadata":{"id":"8iEp0d4RLFwz","executionInfo":{"status":"ok","timestamp":1734301152304,"user_tz":180,"elapsed":177117,"user":{"displayName":"Bruno Alencar Vieira de Rezende","userId":"01054554116542735806"}}},"execution_count":81,"outputs":[]},{"cell_type":"code","source":["id_to_en = {v: k for k, v in src_vocab.items()}\n","id_to_de = {v: k for k, v in trg_vocab.items()}"],"metadata":{"id":"tUQN2bWdTZ-w","executionInfo":{"status":"ok","timestamp":1734308868460,"user_tz":180,"elapsed":222,"user":{"displayName":"Bruno Alencar Vieira de Rezende","userId":"01054554116542735806"}}},"execution_count":96,"outputs":[]},{"cell_type":"code","source":["def preprocess_translation(example, src_vocab, trg_vocab):\n","  src_text = word_tokenize(example[\"translation\"][\"en\"].lower())\n","  trg_text = word_tokenize(example[\"translation\"][\"de\"].lower())\n","\n","  src_ids = [src_vocab.get(token, src_vocab[\"<UNK>\"]) for token in src_text]\n","  trg_ids = [trg_vocab.get(token, trg_vocab[\"<UNK>\"]) for token in trg_text]\n","\n","  return (\n","    [src_vocab[\"<SOS>\"]] + src_ids + [src_vocab[\"<EOS>\"]],\n","    [trg_vocab[\"<SOS>\"]] + trg_ids + [trg_vocab[\"<EOS>\"]],\n","  )\n","\n","train_data_pairs = [\n","    preprocess_translation(example, src_vocab, trg_vocab) for example in dataset[\"train\"]\n","]\n","validation_data_pairs = [\n","    preprocess_translation(example, src_vocab, trg_vocab) for example in dataset[\"validation\"]\n","]\n","test_data_pairs = [\n","    preprocess_translation(example, src_vocab, trg_vocab) for example in dataset[\"test\"]\n","]"],"metadata":{"id":"HYxM3YRoL529","executionInfo":{"status":"ok","timestamp":1734301365140,"user_tz":180,"elapsed":212838,"user":{"displayName":"Bruno Alencar Vieira de Rezende","userId":"01054554116542735806"}}},"execution_count":83,"outputs":[]},{"cell_type":"code","source":["print(train_data_pairs[0])\n","dataset[\"train\"][0]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"oJzddK5PMbNR","executionInfo":{"status":"ok","timestamp":1734301365141,"user_tz":180,"elapsed":4,"user":{"displayName":"Bruno Alencar Vieira de Rezende","userId":"01054554116542735806"}},"outputId":"9e8a0257-784c-420a-b0d2-efb4f36561fa"},"execution_count":84,"outputs":[{"output_type":"stream","name":"stdout","text":["([1, 5090, 7, 4, 1621, 2], [1, 3606, 7, 3137, 2])\n"]},{"output_type":"execute_result","data":{"text/plain":["{'translation': {'de': 'Wiederaufnahme der Sitzungsperiode',\n","  'en': 'Resumption of the session'}}"]},"metadata":{},"execution_count":84}]},{"cell_type":"code","source":["def pad_sequence(seq, max_length, pad_idx):\n","  return seq + [pad_idx] * (max_length - len(seq)) if len(seq) < max_length else seq[:max_length]"],"metadata":{"id":"Gd0ByrYhMtb0","executionInfo":{"status":"ok","timestamp":1734301365141,"user_tz":180,"elapsed":3,"user":{"displayName":"Bruno Alencar Vieira de Rezende","userId":"01054554116542735806"}}},"execution_count":85,"outputs":[]},{"cell_type":"code","source":["class TranslationDataset(Dataset):\n","  def __init__(self, data, src_pad_idx, trg_pad_idx, max_length=50):\n","    self.data = data\n","    self.src_pad_idx = src_pad_idx\n","    self.trg_pad_idx = trg_pad_idx\n","    self.max_length = max_length\n","\n","  def __len__(self):\n","    return len(self.data)\n","\n","  def __getitem__(self, idx):\n","    src, trg = self.data[idx]\n","    src = pad_sequence(src, self.max_length, self.src_pad_idx)\n","    trg = pad_sequence(trg, self.max_length, self.trg_pad_idx)\n","    return torch.tensor(src), torch.tensor(trg)"],"metadata":{"id":"8A13RS1vM1ao","executionInfo":{"status":"ok","timestamp":1734301365142,"user_tz":180,"elapsed":4,"user":{"displayName":"Bruno Alencar Vieira de Rezende","userId":"01054554116542735806"}}},"execution_count":86,"outputs":[]},{"cell_type":"code","source":["src_pad_idx = src_vocab[\"<PAD>\"]\n","trg_pad_idx = trg_vocab[\"<PAD>\"]\n","\n","train_dataset = TranslationDataset(train_data_pairs, src_pad_idx, trg_pad_idx)\n","validation_dataset = TranslationDataset(validation_data_pairs, src_pad_idx, trg_pad_idx)\n","test_dataset = TranslationDataset(test_data_pairs, src_pad_idx, trg_pad_idx)\n","\n","train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n","validation_loader = DataLoader(validation_dataset, batch_size=64, shuffle=True)\n","test_loader = DataLoader(test_dataset, batch_size=64, shuffle=True)"],"metadata":{"id":"d6JICcsVNFHz","executionInfo":{"status":"ok","timestamp":1734301365142,"user_tz":180,"elapsed":4,"user":{"displayName":"Bruno Alencar Vieira de Rezende","userId":"01054554116542735806"}}},"execution_count":87,"outputs":[]},{"cell_type":"markdown","source":["# Tranining The Transformer"],"metadata":{"id":"EfkKu58fNLOY"}},{"cell_type":"code","source":["def evaluate_model(loader, model, criterion, device):\n","  model.eval()\n","  total_loss = 0\n","\n","  with torch.no_grad():\n","    for src, trg in loader:\n","      src, trg = src.to(device), trg.to(device)\n","\n","      output = model(src, trg[:, :-1])\n","      output = output.reshape(-1, output.shape[2])\n","      trg = trg[:, 1:].reshape(-1)\n","\n","      loss = criterion(output, trg)\n","      total_loss += loss.item()\n","\n","  return total_loss / len(loader)"],"metadata":{"id":"EzA-rHcIV_5v","executionInfo":{"status":"ok","timestamp":1734301365142,"user_tz":180,"elapsed":3,"user":{"displayName":"Bruno Alencar Vieira de Rezende","userId":"01054554116542735806"}}},"execution_count":88,"outputs":[]},{"cell_type":"code","source":["src_vocab_size = len(src_vocab)\n","trg_vocab_size = len(trg_vocab)\n","model = Transformer(\n","    src_vocab_size=src_vocab_size,\n","    trg_vocab_size=trg_vocab_size,\n","    src_pad_idx=src_pad_idx,\n","    trg_pad_idx=trg_pad_idx,\n","    device=device,\n",").to(device)\n","\n","criterion = nn.CrossEntropyLoss(ignore_index=src_pad_idx)\n","optimizer = optim.Adam(model.parameters(), lr=3e-4)\n","\n","EPOCHS = 3\n","\n","for epoch in range(EPOCHS):\n","  model.train()\n","  loop = tqdm(train_loader, leave=True)\n","  epoch_loss = 0\n","  for batch_idx, (src, trg) in enumerate(loop):\n","    src, trg = src.to(device), trg.to(device)\n","\n","    output = model(src, trg[:, :-1])\n","    output = output.reshape(-1, output.shape[2])\n","    trg = trg[:, 1:].reshape(-1)\n","\n","    loss = criterion(output, trg)\n","    epoch_loss += loss.item()\n","\n","    optimizer.zero_grad()\n","    loss.backward()\n","    optimizer.step()\n","\n","    loop.set_description(f\"Epoch [{epoch+1}/{EPOCHS}]\")\n","    loop.set_postfix(loss=loss.item())\n","\n","  val_loss = evaluate_model(validation_loader, model, criterion, device)\n","  print(f\"Epoch {epoch+1} completed. Training Loss: {epoch_loss / len(train_loader):.4f}, Validation Loss: {val_loss:.4f}\")\n","\n","test_loss = evaluate_model(test_loader, model, criterion, device)\n","print(f\"Test Loss: {test_loss:.4f}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"GqwIwjZVNKbT","executionInfo":{"status":"ok","timestamp":1734308737104,"user_tz":180,"elapsed":1914726,"user":{"displayName":"Bruno Alencar Vieira de Rezende","userId":"01054554116542735806"}},"outputId":"8aa18c58-167a-498c-cd2a-400a31b9a7aa"},"execution_count":90,"outputs":[{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["Epoch [1/3]: 100%|██████████| 7813/7813 [40:38<00:00,  3.20it/s, loss=1.97]\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Epoch 1 completed. Training Loss: 2.9196, Validation Loss: 2.5239\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["Epoch [2/3]: 100%|██████████| 7813/7813 [40:33<00:00,  3.21it/s, loss=2.07]\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Epoch 2 completed. Training Loss: 1.9441, Validation Loss: 2.3028\n"]},{"output_type":"stream","name":"stderr","text":["Epoch [3/3]: 100%|██████████| 7813/7813 [40:32<00:00,  3.21it/s, loss=1.57]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 3 completed. Training Loss: 1.7412, Validation Loss: 2.2023\n","Test Loss: 2.1899\n"]}]},{"cell_type":"code","source":["test_loss = evaluate_model(test_loader, model, criterion, device)"],"metadata":{"id":"BsbZHTHSWMog","executionInfo":{"status":"aborted","timestamp":1734301407337,"user_tz":180,"elapsed":5,"user":{"displayName":"Bruno Alencar Vieira de Rezende","userId":"01054554116542735806"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(test_loss)"],"metadata":{"id":"z1BRgqSVXQR2","executionInfo":{"status":"aborted","timestamp":1734301407337,"user_tz":180,"elapsed":5,"user":{"displayName":"Bruno Alencar Vieira de Rezende","userId":"01054554116542735806"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def translate_sentence(sentence, model, src_vocab, trg_vocab, src_pad_idx, trg_pad_idx, max_length=50, device=\"cpu\"):\n","  model.eval()\n","\n","  tokens = word_tokenize(sentence.lower())\n","  src_ids = [src_vocab.get(token, src_vocab[\"<UNK>\"]) for token in tokens]\n","  src_ids = [src_vocab[\"<SOS>\"]] + src_ids + [src_vocab[\"<EOS>\"]]\n","\n","  src_ids = src_ids + [src_pad_idx] * (max_length - len(src_ids)) if len(src_ids) < max_length else src_ids[:max_length]\n","  src_tensor = torch.tensor(src_ids, dtype=torch.long).unsqueeze(0).to(device)\n","\n","  trg_ids = [trg_vocab[\"<SOS>\"]]\n","\n","  for _ in range(max_length):\n","    trg_tensor = torch.tensor(trg_ids, dtype=torch.long).unsqueeze(0).to(device)  # Add batch dimension\n","\n","    with torch.no_grad():\n","      output = model(src_tensor, trg_tensor)\n","\n","    next_token = output.argmax(dim=-1)[:, -1].item()\n","\n","    trg_ids.append(next_token)\n","\n","    if next_token == trg_vocab[\"<EOS>\"]:\n","      break\n","\n","  trg_tokens = [id_to_de[id] for id in trg_ids]\n","\n","  translated_sentence = \" \".join(trg_tokens[1:-1])\n","\n","  return translated_sentence"],"metadata":{"id":"MIRDxTaGRarf","executionInfo":{"status":"ok","timestamp":1734308760139,"user_tz":180,"elapsed":234,"user":{"displayName":"Bruno Alencar Vieira de Rezende","userId":"01054554116542735806"}}},"execution_count":91,"outputs":[]},{"cell_type":"code","source":["input_sentence = \"Hello, how are you?\"\n","\n","translated_sentence = translate_sentence(\n","    sentence=input_sentence,\n","    model=model,\n","    src_vocab=src_vocab,\n","    trg_vocab=trg_vocab,\n","    src_pad_idx=src_vocab[\"<PAD>\"],\n","    trg_pad_idx=trg_vocab[\"<PAD>\"],\n","    max_length=50,\n","    device=device\n",")\n","\n","print(f\"Translated Sentence: {translated_sentence}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ODRIyVFGRyvt","executionInfo":{"status":"ok","timestamp":1734308773146,"user_tz":180,"elapsed":254,"user":{"displayName":"Bruno Alencar Vieira de Rezende","userId":"01054554116542735806"}},"outputId":"ee8182e5-3e92-4322-8bd0-633bc481b4b3"},"execution_count":92,"outputs":[{"output_type":"stream","name":"stdout","text":["Translated Sentence: wie sollen sie denn sein ?\n"]}]},{"cell_type":"code","source":["def evaluate_bleu_score(model, test_loader, src_vocab, trg_vocab, device):\n","  references = []\n","  predictions = []\n","\n","  for src, trg in test_loader:\n","    src = src.to(device)\n","    trg = trg.to(device)\n","\n","    for i in range(src.shape[0]):\n","      src_sentence = [id_to_en[idx] for idx in src[i].tolist() if idx not in [src_pad_idx]]\n","      src_sentence = \" \".join(src_sentence)\n","      reference = [id_to_de[idx] for idx in trg[i].tolist() if idx not in [trg_pad_idx]]\n","      reference = \" \".join(reference)\n","\n","      prediction = translate_sentence(\n","        sentence=src_sentence,\n","        model=model,\n","        src_vocab=src_vocab,\n","        trg_vocab=trg_vocab,\n","        src_pad_idx=src_vocab[\"<PAD>\"],\n","        trg_pad_idx=trg_vocab[\"<PAD>\"],\n","        device=device\n","      )\n","\n","      references.append(reference)\n","      predictions.append(prediction)\n","\n","    print(\"Progress:\", i+1, \"/\", len(test_loader))\n","\n","\n","  smooth_fn = SmoothingFunction().method4\n","  bleu_score = corpus_bleu(references, predictions, smoothing_function=smooth_fn)\n","  return bleu_score\n","\n","bleu = evaluate_bleu_score(model, test_loader, src_vocab, trg_vocab, device)\n","print(f\"BLEU Score: {bleu:.4f}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":366},"id":"42ND4xYQkr2O","executionInfo":{"status":"error","timestamp":1734309678079,"user_tz":180,"elapsed":64548,"user":{"displayName":"Bruno Alencar Vieira de Rezende","userId":"01054554116542735806"}},"outputId":"5debb800-d339-4f20-90f7-bd062b8098e6"},"execution_count":109,"outputs":[{"output_type":"stream","name":"stdout","text":["Progress: 64 / 47\n"]},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-109-ba292813efec>\u001b[0m in \u001b[0;36m<cell line: 35>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     33\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mbleu_score\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m \u001b[0mbleu\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mevaluate_bleu_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msrc_vocab\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrg_vocab\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     36\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"BLEU Score: {bleu:.4f}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-109-ba292813efec>\u001b[0m in \u001b[0;36mevaluate_bleu_score\u001b[0;34m(model, test_loader, src_vocab, trg_vocab, device)\u001b[0m\n\u001b[1;32m     13\u001b[0m       \u001b[0mreference\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\" \"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreference\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m       prediction = translate_sentence(\n\u001b[0m\u001b[1;32m     16\u001b[0m         \u001b[0msentence\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msrc_sentence\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-91-c5416118d681>\u001b[0m in \u001b[0;36mtranslate_sentence\u001b[0;34m(sentence, model, src_vocab, trg_vocab, src_pad_idx, trg_pad_idx, max_length, device)\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m       \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc_tensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrg_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0mnext_token\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1735\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1736\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1737\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1746\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1748\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-78-15860f2ebba6>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, src, trg)\u001b[0m\n\u001b[1;32m     59\u001b[0m     \u001b[0msrc_mask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_src_mask\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m     \u001b[0mtrg_mask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_trg_mask\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m     \u001b[0menc_src\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msrc_mask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     62\u001b[0m     \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0menc_src\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msrc_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrg_mask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1735\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1736\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1737\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1746\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1748\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-75-1a7bbd3aff1d>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, mask)\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mlayer\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m       \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# values, keys and queries are all the same\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1735\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1736\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1737\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1746\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1748\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-74-9f6b5bfb2321>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, values, keys, queries, mask)\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[0mfeed_forward_out\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeed_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnorm1_out\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m     \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnorm2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeed_forward_out\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mnorm1_out\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# the norm1_out represent the skip connection\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   1919\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m\"_parameters\"\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__dict__\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1920\u001b[0m             \u001b[0m_parameters\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__dict__\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"_parameters\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1921\u001b[0;31m             \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32min\u001b[0m \u001b[0m_parameters\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1922\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0m_parameters\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1923\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m\"_buffers\"\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__dict__\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"cell_type":"code","source":["def evaluate_bleu_score(model, test_loader, src_vocab, trg_vocab, device):\n","  references = []\n","  predictions = []\n","\n","  progress_counter = threading.Lock()\n","  completed_batches = 0\n","\n","  def process_batch_item(idx):\n","    src_sentence = [id_to_en[token] for token in src[idx].tolist() if token not in [src_pad_idx]]\n","    src_sentence = \" \".join(src_sentence)\n","\n","    reference = [id_to_de[token] for token in trg[idx].tolist() if token not in [trg_pad_idx]]\n","    reference = \" \".join(reference)\n","\n","    prediction = translate_sentence(\n","      sentence=src_sentence,\n","      model=model,\n","      src_vocab=src_vocab,\n","      trg_vocab=trg_vocab,\n","      src_pad_idx=src_vocab[\"<PAD>\"],\n","      trg_pad_idx=trg_vocab[\"<PAD>\"],\n","      device=device\n","    )\n","    return reference, prediction\n","\n","  for batch_idx, (src, trg) in enumerate(test_loader):\n","    src = src.to(device)\n","    trg = trg.to(device)\n","\n","    with ThreadPoolExecutor() as executor:\n","      results = list(executor.map(process_batch_item, range(src.shape[0])))\n","\n","    with progress_counter:\n","      for reference, prediction in results:\n","        references.append(reference)\n","        predictions.append(prediction)\n","\n","      completed_batches += 1\n","      print(f\"Progress: {completed_batches} / {len(test_loader)}\")\n","\n","  smooth_fn = SmoothingFunction().method4\n","  bleu_score = corpus_bleu(references, predictions, smoothing_function=smooth_fn)\n","  return bleu_score\n","\n","bleu = evaluate_bleu_score(model, test_loader, src_vocab, trg_vocab, device)\n","print(f\"BLEU Score: {bleu:.4f}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"tdIZwXEh6bTS","executionInfo":{"status":"ok","timestamp":1734311600049,"user_tz":180,"elapsed":1751287,"user":{"displayName":"Bruno Alencar Vieira de Rezende","userId":"01054554116542735806"}},"outputId":"b1ee9b82-4668-4cb0-f9e8-7dc5f68671cc"},"execution_count":113,"outputs":[{"output_type":"stream","name":"stdout","text":["Progress: 1 / 47\n","Progress: 2 / 47\n","Progress: 3 / 47\n","Progress: 4 / 47\n","Progress: 5 / 47\n","Progress: 6 / 47\n","Progress: 7 / 47\n","Progress: 8 / 47\n","Progress: 9 / 47\n","Progress: 10 / 47\n","Progress: 11 / 47\n","Progress: 12 / 47\n","Progress: 13 / 47\n","Progress: 14 / 47\n","Progress: 15 / 47\n","Progress: 16 / 47\n","Progress: 17 / 47\n","Progress: 18 / 47\n","Progress: 19 / 47\n","Progress: 20 / 47\n","Progress: 21 / 47\n","Progress: 22 / 47\n","Progress: 23 / 47\n","Progress: 24 / 47\n","Progress: 25 / 47\n","Progress: 26 / 47\n","Progress: 27 / 47\n","Progress: 28 / 47\n","Progress: 29 / 47\n","Progress: 30 / 47\n","Progress: 31 / 47\n","Progress: 32 / 47\n","Progress: 33 / 47\n","Progress: 34 / 47\n","Progress: 35 / 47\n","Progress: 36 / 47\n","Progress: 37 / 47\n","Progress: 38 / 47\n","Progress: 39 / 47\n","Progress: 40 / 47\n","Progress: 41 / 47\n","Progress: 42 / 47\n","Progress: 43 / 47\n","Progress: 44 / 47\n","Progress: 45 / 47\n","Progress: 46 / 47\n","Progress: 47 / 47\n","BLEU Score: 0.0000\n"]}]}]}